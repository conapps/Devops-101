| [<-- Volver](20170801-Docker.md) |
[Siguiente -->](20170815-Storage.md) |

## Imágenes y contenedores
---

Hasta ahora hemos creado contenedores provenientes de imagenes creadas por terceros. Ahora vamos a explorar los pasos necesarios para crear nuestras propias imágenes.

### Docker commit

Supongamos que generamos un container a partir de la última imagen de ubuntu de la siguiente manera:

```bash
$ docker run --name segunda-prueba -i -t ubuntu bash
root@1dbc76e3acdb:/#
```

Esto nos deja posicionados dentro de este nuevo contenedor, esto es gracias a las opciones ```-i``` que conecta la entrada estándar, en este caso el teclado, al contenedor generando una sesión interactiva y ```-t``` que asigna un terminal virtual al contenedor redirigiendo su salida estándar al monitor. Podemos ver que estamos dentro del contenedor y no dentro de nuestra máquina al observar el prompt, que como puede verse el en cuadro de texto mas arriba debería ser del estilo ```root@1dbc76e3acdb:/#```.

Supongamos ahora que queremos abrir un intérprete de Python:

```bash
root@1dbc76e3acdb:/# python
bash: python: command not found
```
El problema aquí es que Python no está instalado, a continuación lo instalamos:

```bash
root@e6387986f32b:/# apt-get update && apt-get install -y python
Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [102 kB]
Get:2 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]
Get:3 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [43.0 kB]
Get:4 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [406 kB]
Get:5 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [102 kB]         
Get:6 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.8 kB]
Get:7 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [187 kB]
Get:8 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [2931 B]
----> SALIDA OMITIDA PARA MAYOR CLARIDAD <---
```

Una vez finalizado el proceso de instalación ya podemos utilizar Python:

```bash
root@e6387986f32b:/# python
Python 2.7.12 (default, Nov 19 2016, 06:48:10)
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>>
>>>
>>>
>>> exit()
root@e6387986f32b:/#
```

En este punto tenemos un contenedor completamente funcional que cumple con todas nuestras necesidades, en este caso únicamente Python.
Pero que sucede si ahora queremos utilizar este contenedor en producción fuera de nuestra máquina local. Esto de hecho es una de las fortalezas mas importantes de la tecnología de contenedores, esto es, la posibilidad de crear un ambiente en nuestra máquina local y luego exportar y utilizar dicho ambiente en producción con exactamente los mismos paquetes y dependencias instaladas que lo que tenemos localmente (lo que utilizamos para desarrollar).
El problema aquí es que, a diferencia del transporte marítimo, en Docker lo que se transporta no son los contenedores sino las imágenes y a partir de una imagen se pueden generar cualquier cantidad de contenedores idénticos.
Dicho esto, si queremos transportar nuestro nuevo ambiente con Python instalado sobre una distribución Ubuntu, el desafío es generar una nueva imagen, dado que la imagen de la cual partimos no contiene Python. Para esto utilizaremos el comando ```docker commit <contenedor> <nombre-de-la-nueva-imagen>```, por ejemplo:

```$
$ docker commit segunda-prueba ambiente-produccion
sha256:c2a9520001342c424d141f05c6f13761a74d58edd336f11b7a971c1a1d2ed317
$ docker images
REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
ambiente-produccion       latest              c2a952000134        5 seconds ago       189.2 MB
```

Ahora que tengo una nueva imagen desde la cual generar contenedores con mi ambiente, podría eliminar el contenedor y volver a regenerarlo. Como se puede ver en el cuadro a continuación el nuevo contenedor ya tiene Python instalado:

```bash
$ docker rm segunda-prueba
segunda-prueba

$ docker run --name tercera-prueba -it ambiente-produccion bash
root@0f66ed1e694d:/# python
Python 2.7.12 (default, Nov 19 2016, 06:48:10)
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>>
>>> exit()
root@0f66ed1e694d:/#
root@0f66ed1e694d:/#
```

### Dockerfile

El método anterior sirve para generar imágenes a partir de contenedores, pero tiene muchas desventajas a la hora de su uso en producción.
Es poco flexible y la imagen no está optimizada para versionarse al igual que hacemos con nuestro código. Profundicemos sobre este punto con un ejemplo.
Supongamos que nuestro ambiente de producción no incluye únicamente Python, sino también python3-pip, mysql-connector, requests, nginx, Django, MySQL, open-ssh, y tpftpd-hpa.
Pensemos en el proceso para armar un ambiente de este tipo; habría que generar un contenedor con Ubuntu, instalar todos estos paquetes y luego hacer un commit. Ahora, ¿qué pasaría si durante nuestro proceso de desarrollo decidimos explorar la posiblidad de cambiar nuestro motor de base de datos de MySQL a PostgreSQL? ¿Cómo haríamos para generar una nueva imágen? Podríamos intentar desinstalar MySQL e instalar PostgreSQL en su lugar, pero veamos que hay dependencias como mysql-connector que sólo tienen sentido si utilizamos MySQL y que deberían también ser desinstaladas para mantener "limpia" nuestra imagen que luego será utilzada en producción. Finalmente habría que instalar los módulos de Python correspondientes para trabajar con una base de datos PostgreSQL y hacer un commit para generar la nueva imagen.

Principales desventajas del enfoque anterior:

  - Si la desición de cambiar a PostgreSQL se toma varias semanas o meses luego de generada la primer imagen, probablemente no recuerde que existían las librerías de Python que Soportan MySQL (mysql-connector) dado que los paquetes que hay instalados en la imagen no quedan documentados en ningún sitio (en realidad se pueden ver con el comando ```docker history``` pero esto no es práctico).
  - Los cambios en los ambientes de desarrollo pueden darse decenas de veces en el transcurso de un proyecto, la desinstalación de módulos y librerías que ya no son necesarias puede volverse una tarea tediosa.
  - En general cada cambio en el ambiente de desarrollo viene acompañado por un cambio en el código fuente de nuestra aplicación, lo que nos gustaría poder hacer es versionar nuestro ambiente utilizando los mismos mecanismos (GIT) que utilizamos para versionar nuestro código. Pero cada nueva imagen generada con el método ```$ docker commit``` pesa cientos de Megas y no contiene información de los paquetes que hay instalados en ella.
  - Si queremos reutilizar nuestro ambiente para otro desarrollo no tenemos visibilidad de qué software hay instalado en la imagen para poder adaptarlo a las necesidades del nuevo proyecto.
  - En caso de que el proceso que necesitamos correr en nuestro contenedor no sea "bash", ni siquiera hay una forma sencilla y directa de generar el ambiente utilizando esta estrategia de ```docker commit```.

La solución a los problemas planteados anteriormente es la utilización de un archivo 'Dockerfile' para la construcción de nuestra imagen.
Un archivo 'Dockerfile' es básicamente un archivo de texto que describe de forma unívoca cuál es el contenido de la imagen. Para entenderlo mejor, veamos como aplicaríamos esta técnica para la confección de la imagen del ejemplo anterior.
El contenido del archivo 'Dockerfile' sería el siguiente:

```
FROM ubuntu
LABEL maintainer="ialmandos@conatel.com.uy"
ADD config.txt /settings/config.txt
RUN apt-get update
RUN apt-get install -y python3
RUN apt-get install -y python3-pip
RUN pip3 install --upgrade pip
RUN pip3 install requests
RUN pip3 install mysql-connector==2.1.4
RUN pip3 install django==1.10
RUN echo "mysql-server mysql-server/root_password password C0n4t3l2017." | debconf-set-selections
RUN echo "mysql-server mysql-server/root_password_again password C0n4t3l2017." | debconf-set-selections
RUN apt-get install -y mysql-server
RUN apt-get install -y tftpd-hpa
RUN apt-get install -y openssh-server
RUN apt-get install -y nginx
CMD bash
```

Una vez que tenemos el archivo Dockerfile armado, lo único que nos resta por hacer para generar la imágen es guardarlo en un directorio vacío, agregar a dicho directorio un archivo ```config.txt``` con contenido arbitrario, posicionarnos con el prompt en dicho directorio y ejecutar:

```bash
$ docker build -t prod-env:0.1 .
```

Esto generará una imágen llamada ```prod-env:0.1``` (0.1 es un string arbitrario que hace referencia a la versión) a partir de la cual podrémos generar la cantidad de contenedores que necesítemos.
Este método tiene las siguientes ventajas:

  - La especificación de la imagen ocupa apenas unos bytes por lo que se vuelve muy sencilla de transportar.
  - El archivo Dockerfile contiene la información exacta de los paqutetes que hay instalados en la imagen.
  - El archivo Dockerfile es totalmente versionable con GIT.
  - Si necesitamos hacer un cambio en nuestro ambiente sólo necesitamos modificar las líneas correspondientes en Dockerfile y volver a generar la imagen. No es necesario instalar y desinstalar paquetes manualmente.

Ahora, si quisiéramos generar un contenedor a partir de la imagen que construímos podríamos ejecutar:

```bash
$ docker run -it prod-env:0.1
root@08322e95d53c:/#
```

A continuación analizaremos cada una de los comandos especificados en Dockerfile para entender cuál es su cometido.

```FROM```
---
Especifíca la imagen base a utilizar, en este caso ```ubuntu:latest```.


```LABEL```
---
Permite agregar metadata de forma arbitraria a la imagen. Esto puede utilizarse con múltiples propósitos, en este caso particular se está utilizando para indicar el correo del "dueño" de la imagen.
Esta medatada puede consultarse con el comando ```docker inspect```.

```bash
$ docker inspect prod-env:0.1
...
...
"Labels": {
    "maintainer": "ialmandos@conatel.com.uy"
}
...
...
```

```ADD```
---
Agrega un archivo o directorio desde el contexto al lugar especificado en el filesystem de la imagen.


```RUN```
---
Ejecuta un comando bash


```CMD```
---
Proceso a ejecutar por defecto en caso de que el usuario no especifique uno al ejecutar ```docker run```.


## Optimización de la construcción de imágenes

Antes de aprender como escribir nuestro archivo Dockerfile para generar nuestras imágenes de forma mas eficiente, es necesario entender como funciona el proceso de construcción de una imágen a bajo nivel.
Cuando creamos una imagen a partir de un archivo Dockerfile con el comando ```docker build```, lo que hace básicamente docker es tomar la imagen base especificada en la directiva ```FROM``` e ir ejecutando de forma secuencial los comandos especificados en las directivas ```RUN```, ejecutando implícitamente un ```docker commit``` luego de cada comando y almacenando la imagen resultante en cache local.
Por lo que, al final del día, tendremos almacenada nuestra imagen final y todas las imágenes intermedias que se fueron creando para llegar a la misma. Esta estructura de capas puede verse al ejecutar el siguiente comando:

```bash
$ docker history prod-env:0.1
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
--> Lineas omitidas para mayor claridad <--
1d20f906abf2        5 minutes ago       /bin/sh -c apt-get install -y python3-pip       259 MB              
262a82549ff1        17 minutes ago      /bin/sh -c apt-get install -y python3           37.28 MB            
65e5f33f7859        18 minutes ago      /bin/sh -c apt-get update                       38.81 MB            
c2b62f673858        21 minutes ago      /bin/sh -c #(nop)  CMD ["/bin/sh" "-c" "bash"   0 B                 
9c2c661471f1        21 minutes ago      /bin/sh -c #(nop) ADD file:f3324fde77ff764cb1   7 B                 
afafd17c2c9c        26 hours ago        /bin/sh -c #(nop)  LABEL maintainer=ialmandos   0 B                 
6a2f32de169d        3 months ago        /bin/sh -c #(nop)  CMD ["/bin/bash"]            0 B                 
<missing>           3 months ago        /bin/sh -c mkdir -p /run/systemd && echo 'doc   7 B                 
<missing>           3 months ago        /bin/sh -c sed -i 's/^#\s*\(deb.*universe\)$/   2.759 kB            
<missing>           3 months ago        /bin/sh -c rm -rf /var/lib/apt/lists/*          0 B                 
<missing>           3 months ago        /bin/sh -c set -xe   && echo '#!/bin/sh' > /u   745 B               
<missing>           3 months ago        /bin/sh -c #(nop) ADD file:b8a2c16d65e533a2bc   117.2 MB
```

El objetivo de la estructura de capas almacenadas en cache es optimizar el tiempo de construcción de las imagenes y el espacio en disco que consumen los contenedores, mas sobre esto [aquí](https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/#images-and-layers). Este proceso funciona de la siguiente manera: al invocar ```docker build -t <nombre-de-la-imagen> .```,  lo que hace Docker es, antes de ejecutar cada directiva del archivo Dockerfile, fijarse si no hay en cache una imagen derivada de la directiva correspondiente y de todas las anteriores (comenzando por la directiva ```FROM``` que siempre es la primera). En caso de que encuentre una imagen que se corresponda con dicha directiva, se saltea el paso de la generación de la misma (porque ya está generada) y pasa a la siguiente directiva. Este proceso se repite hasta que alguna de las imágenes no se encuentre en cache local, en tal caso Docker crea dicha imagen **y todas las sucesivas**. Dicho de otra forma, una imagen está compuesta por capas **read-only** que contienen los archivos resultantes de las directivas ejecutadas desde el archivo Dockerfile; estas capas se construyen una sobre otra, de forma incremental, agregando los archivos "delta" (sólo la diferencia) entre una capa y otra. Dado que las capas son read-only, si una capa posterior modifica un archivo contenido en una capa anterior, es necesario copiar nuevamente el archivo completo en la capa posterior, siéndo esta última copia la que se utilizará. Esta forma de construir las imágenes como capas una sobre otra, tiene la implicancia de que si modificamos una capa "del medio", será necesario volver a generar todas las capas sucesivas, dado que las capas no son autocontenidas sino que se basan en su capa anterior incluyendo únicamente los "nuevos archivos".
Entender esto es la clave para generar archivos Dockerfile mas eficientes; veámoslo con un ejemplo.
Cuando construímos nuestra imagen ```prod-env:0.1``` cargamos en ella una archivo de configuración llamado ```config.txt```. Supongamos ahora que queremos cambiar dicho archivo porque nos interesa modificar la configuración de nuestra aplicación; como la línea ```ADD config.txt /settings/config.txt``` se encuentra en tercer lugar en el archivo Dockerfile, Docker se verá obligado a volver a generar todas las imágenes correspondientes a las líneas 4 en adelante. Si por el contrario nuestro archivo de configuración, que es lo único frecuentemente modificable de nuestra imagen, se encontrara en el último lugar, el proceso de reconstrucción de nuestra imagen sería mucho mas rápido. Los cuadros de texto a continuación muestran el funcionamiento:

**Genero un nuevo archivo Dockerfile**
```
FROM ubuntu
LABEL maintainer="ialmandos@conatel.com.uy"
RUN apt-get update
RUN apt-get install -y python3
RUN apt-get install -y python3-pip
RUN pip3 install --upgrade pip
RUN pip3 install requests
RUN pip3 install mysql-connector==2.1.4
RUN pip3 install django==1.10
RUN echo "mysql-server mysql-server/root_password password C0n4t3l2017." | debconf-set-selections
RUN echo "mysql-server mysql-server/root_password_again password C0n4t3l2017." | debconf-set-selections
RUN apt-get install -y mysql-server
RUN apt-get install -y tftpd-hpa
RUN apt-get install -y openssh-server
RUN apt-get install -y nginx
# Colocamos el archivo config.txt al final de Dockerfile para que el build sea mas rapido
ADD config.txt /settings/config.txt
CMD bash
```

**Construyo la nueva imagen**
```bash
$ docker build -t prod-env:0.2 .
--> Proceso largo, salida omitida para mayor claridad <--
```

**Modifico el archivo de configuración**
```bash
$ nano configuracion.txt
...
```

**Construyo la nueva imagen (Proceso rápido)**
```bash
$ docker build -t prod-env:0.3 .
Sending build context to Docker daemon 3.584 kB
Step 1 : FROM ubuntu
 ---> 6a2f32de169d
Step 2 : LABEL maintainer "ialmandos@conatel.com.uy"
 ---> Using cache
 ---> afafd17c2c9c
Step 3 : RUN apt-get update
 ---> Using cache
 ---> 573326a6e92c
Step 4 : RUN apt-get install -y python3
 ---> Using cache
 ---> 5bfb4979116a
Step 5 : RUN apt-get install -y python3-pip
 ---> Using cache
 ---> c61e1f9186a9
Step 6 : RUN pip3 install --upgrade pip
 ---> Using cache
 ---> a8c50dcc2edb
Step 7 : RUN pip3 install requests
 ---> Using cache
 ---> 839dc6e481dd
Step 8 : RUN pip3 install mysql-connector==2.1.4
 ---> Using cache
 ---> 5a79ea4f45e8
Step 9 : RUN pip3 install django==1.10
 ---> Using cache
 ---> 3e4141f48995
Step 10 : RUN echo "mysql-server mysql-server/root_password password C0n4t3l2017." | debconf-set-selections
 ---> Using cache
 ---> 127612294c11
Step 11 : RUN echo "mysql-server mysql-server/root_password_again password C0n4t3l2017." | debconf-set-selections
 ---> Using cache
 ---> 9dad58c90c5e
Step 12 : RUN apt-get install -y mysql-server
 ---> Using cache
 ---> e3890c3a7f44
Step 13 : RUN apt-get install -y tftpd-hpa
 ---> Using cache
 ---> 1ed09e6b67a8
Step 14 : RUN apt-get install -y openssh-server
 ---> Using cache
 ---> cb7c94f932b9
Step 15 : RUN apt-get install -y nginx
 ---> Using cache
 ---> e9dedac9236d
Step 16 : ADD config.txt /settings/config.txt
 ---> 3d8725e97b1d
Removing intermediate container f9220859e7e8
Step 17 : CMD bash
 ---> Running in 6ae16bd2cb01
 ---> ddcc775bb256
Removing intermediate container 6ae16bd2cb01
```

### Contenedores vs imágenes

Si bien conceptualmente las diferencias entre contenedores e imágenes son importantes, la realidad es que si análizamos uno y otro a bajo nivel, tienen una estructura casí idéntica. De hecho la imagen es parte del contenedor; veamos esto en mas detalle.
Un contenedor es una imagen a la que se le agrega una capa adicional con permisos de escritura. Esta capa contendrá todos los archivos que se generen en el contenedor mientras el mismo esté corriendo. Esta capa con permiso de escritura permanecerá en nuestro sistema haciendo persistentes los datos contenidos en ella mientras el contenedor exista; cuando borramos un contenedor de nuestro sistema con el comando ```docker rm <nombre-del-contenedor>``` lo que en realidad estamos haciendo es borrar esta última capa. La imagen a continuación muestra gráficamente la estructura de capas explicada anteriormente:

![alt text](container-layers.jpg "Estructura de capas de un contenedor")

La forma en que están estructurados los contenedores presenta un beneficio muy importante, y es que si corremos varios conenedores derivados de una misma imagen, el espacio que ocupará cada uno en disco será unicamente la sumatoria de todas las capas superiores (capas de contenedor) mas la imagen en sí, que se sumará una única vez. El diagrama a continuación muestra este concepto gráficamente:

![alt text](sharing-layers.jpg "Varios contenedores utilizando una imagen")

| [<-- Volver](20170801-Docker.md) |
[Siguiente -->](20170815-Storage.md) |
