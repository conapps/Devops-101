| [<-- Volver](20170801-Docker.md) |
[Siguiente -->](20170815-Storage.md) |

## Imágenes y contenedores
---

Hasta ahora hemos creado contenedores provenientes de imagenes creadas por terceros. Ahora vamos a explorar los pasos necesarios para crear nuestras propias imágenes.

### Docker commit

Supongamos que generamos un container a partir de la última imagen de ubuntu de la siguiente manera:

```bash
$ docker run --name ejemplo_commit -i -t ubuntu bash
root@1dbc76e3acdb:/#
```

Esto nos deja posicionados dentro de este nuevo contenedor, esto es gracias a las opciones ```-i``` que conecta la entrada estándar, en este caso el teclado, al contenedor generando una sesión interactiva y ```-t``` que asigna un terminal virtual al contenedor redirigiendo su salida estándar al monitor. Podemos ver que estamos dentro del contenedor y no dentro de nuestra máquina al observar el prompt, que como puede verse el en cuadro de texto mas arriba debería ser del estilo ```root@1dbc76e3acdb:/#```.

Supongamos ahora que queremos abrir un intérprete de Python:

```bash
root@1dbc76e3acdb:/# python
bash: python: command not found
```
El problema aquí es que Python no está instalado, a continuación lo instalamos:

```bash
root@e6387986f32b:/# apt-get update && apt-get install -y python
Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [102 kB]
Get:2 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]
Get:3 http://security.ubuntu.com/ubuntu xenial-security/universe Sources [43.0 kB]
Get:4 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [406 kB]
Get:5 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [102 kB]         
Get:6 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.8 kB]
Get:7 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [187 kB]
Get:8 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [2931 B]
----> SALIDA OMITIDA PARA MAYOR CLARIDAD <---
```

Una vez finalizado el proceso de instalación ya podemos utilizar Python:

```bash
root@e6387986f32b:/# python
Python 2.7.12 (default, Nov 19 2016, 06:48:10)
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>>
>>>
>>>
>>> exit()
root@e6387986f32b:/#
```

En este punto tenemos un contenedor completamente funcional que cumple con todas nuestras necesidades, en este caso únicamente Python.
Pero que sucede si ahora queremos utilizar este contenedor en producción fuera de nuestra máquina local. Esto de hecho es una de las fortalezas mas importantes de la tecnología de contenedores, esto es, la posibilidad de crear un ambiente en nuestra máquina local y luego exportar y utilizar dicho ambiente en producción con exactamente los mismos paquetes y dependencias instaladas que lo que tenemos localmente (lo que utilizamos para desarrollar).
El problema aquí es que, a diferencia del transporte marítimo, en Docker lo que se transporta no son los contenedores sino las imágenes y a partir de una imagen se pueden generar cualquier cantidad de contenedores idénticos.
Dicho esto, si queremos transportar nuestro nuevo ambiente con Python instalado sobre una distribución Ubuntu, el desafío es generar una nueva imagen, dado que la imagen de la cual partimos no contiene Python. Para esto utilizaremos el comando ```docker commit <contenedor> <nombre-de-la-nueva-imagen>```, por ejemplo:

```bash
$ docker commit ejemplo_commit ambiente-produccion
sha256:c2a9520001342c424d141f05c6f13761a74d58edd336f11b7a971c1a1d2ed317
$ docker images
REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
ambiente-produccion       latest              c2a952000134        5 seconds ago       189.2 MB
```

Ahora que tengo una nueva imagen desde la cual generar contenedores con mi ambiente, podría eliminar el contenedor y volver a regenerarlo. Como se puede ver en el cuadro a continuación el nuevo contenedor ya tiene Python instalado:

```bash
$ docker rm ejemplo_commit
ejemplo_commit

$ docker run --name contenedor_con_python -it ambiente-produccion bash
root@0f66ed1e694d:/# python
Python 2.7.12 (default, Nov 19 2016, 06:48:10)
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>>
>>> exit()
root@0f66ed1e694d:/#
root@0f66ed1e694d:/#
```

#### Ejercicio 4

1. Partiendo de la última imagen de Ubuntu, generar un contenedor corriendo el proceso `bash`de forma interactiva. 
2. Una vez dentro del contenedor, intentar ejecutar el editor de texto `nano` y verficar que no está instalado.
3. Instalarlo y verficar que se puede correr.
4. Utilizando `docker commit` generar una nueva imagen de Ubuntu con `nano` instalado.
5. A partir de la nueva imagen, generar un nuevo contenedor y verficiar que se puede correr `nano`.

### Dockerfile

El método anterior sirve para generar imágenes a partir de contenedores, pero tiene muchas desventajas a la hora de su uso en producción.
Es poco flexible y la imagen no está optimizada para versionarse al igual que hacemos con nuestro código. Profundicemos sobre este punto con un ejemplo.
Supongamos que nuestro ambiente de producción no incluye únicamente Python, sino también python3-pip, mysql-connector, requests, nginx, Django, MySQL, open-ssh, y tpftpd-hpa.
Pensemos en el proceso para armar un ambiente de este tipo; habría que generar un contenedor con Ubuntu, instalar todos estos paquetes y luego hacer un commit. Ahora, ¿qué pasaría si durante nuestro proceso de desarrollo decidimos explorar la posiblidad de cambiar nuestro motor de base de datos de MySQL a PostgreSQL? ¿Cómo haríamos para generar una nueva imágen? Podríamos intentar desinstalar MySQL e instalar PostgreSQL en su lugar, pero veamos que hay dependencias como mysql-connector que sólo tienen sentido si utilizamos MySQL y que deberían también ser desinstaladas para mantener "limpia" nuestra imagen que luego será utilzada en producción. Finalmente habría que instalar los módulos de Python correspondientes para trabajar con una base de datos PostgreSQL y hacer un commit para generar la nueva imagen.

Principales desventajas del enfoque anterior:

  - Si la desición de cambiar a PostgreSQL se toma varias semanas o meses luego de generada la primer imagen, probablemente no recuerde que existían las librerías de Python que Soportan MySQL (mysql-connector) dado que los paquetes que hay instalados en la imagen no quedan documentados en ningún sitio (en realidad se pueden ver con el comando ```docker history``` pero esto no es práctico).
  - Los cambios en los ambientes de desarrollo pueden darse decenas de veces en el transcurso de un proyecto, la desinstalación de módulos y librerías que ya no son necesarias puede volverse una tarea tediosa.
  - En general cada cambio en el ambiente de desarrollo viene acompañado por un cambio en el código fuente de nuestra aplicación, lo que nos gustaría poder hacer es versionar nuestro ambiente utilizando los mismos mecanismos (GIT) que utilizamos para versionar nuestro código. Pero cada nueva imagen generada con el método ```$ docker commit``` pesa cientos de Megas y no contiene información de los paquetes que hay instalados en ella.
  - Si queremos reutilizar nuestro ambiente para otro desarrollo no tenemos visibilidad de qué software hay instalado en la imagen para poder adaptarlo a las necesidades del nuevo proyecto.
  - En caso de que el proceso que necesitamos correr en nuestro contenedor no sea "bash", ni siquiera hay una forma sencilla y directa de generar el ambiente utilizando esta estrategia de ```docker commit```.

La solución a los problemas planteados anteriormente es la utilización de un archivo 'Dockerfile' para la construcción de nuestra imagen.
Un archivo 'Dockerfile' es básicamente un archivo de texto que describe de forma unívoca cuál es el contenido de la imagen. Para entenderlo mejor, veamos como aplicaríamos esta técnica para la confección de la imagen del ejemplo anterior.
El contenido del archivo 'Dockerfile' sería el siguiente:

```
FROM ubuntu
LABEL maintainer="ialmandos@conatel.com.uy"
ADD config.txt /settings/config.txt
RUN apt-get update
RUN apt-get install -y python3
RUN apt-get install -y python3-pip
RUN pip3 install --upgrade pip
RUN pip3 install requests
RUN pip3 install mysql-connector==2.1.4
RUN pip3 install django==1.10
RUN echo "mysql-server mysql-server/root_password password C0n4t3l2017." | debconf-set-selections
RUN echo "mysql-server mysql-server/root_password_again password C0n4t3l2017." | debconf-set-selections
RUN apt-get install -y mysql-server
RUN apt-get install -y tftpd-hpa
RUN apt-get install -y openssh-server
RUN apt-get install -y nginx
CMD bash
```

Una vez que tenemos el archivo Dockerfile armado, lo único que nos resta por hacer para generar la imágen es guardarlo en un directorio vacío, agregar a dicho directorio un archivo ```config.txt``` con contenido arbitrario, posicionarnos con el prompt en dicho directorio y ejecutar:

```bash
$ docker build -t prod-env:0.1 .
```

Esto generará una imágen llamada ```prod-env:0.1``` (0.1 es un string arbitrario que hace referencia a la versión) a partir de la cual podrémos generar la cantidad de contenedores que necesítemos.
Este método tiene las siguientes ventajas:

  - La especificación de la imagen ocupa apenas unos bytes por lo que se vuelve muy sencilla de transportar.
  - El archivo Dockerfile contiene la información exacta de los paqutetes que hay instalados en la imagen.
  - El archivo Dockerfile es totalmente versionable con GIT.
  - Si necesitamos hacer un cambio en nuestro ambiente sólo necesitamos modificar las líneas correspondientes en Dockerfile y volver a generar la imagen. No es necesario instalar y desinstalar paquetes manualmente.

Ahora, si quisiéramos generar un contenedor a partir de la imagen que construímos podríamos ejecutar:

```bash
$ docker run -it prod-env:0.1
root@08322e95d53c:/#
```

A continuación analizaremos cada una de los comandos especificados en Dockerfile para entender cuál es su cometido.

```FROM```
---
Especifíca la imagen base a utilizar, en este caso ```ubuntu:latest```.


```LABEL```
---
Permite agregar metadata de forma arbitraria a la imagen. Esto puede utilizarse con múltiples propósitos, en este caso particular se está utilizando para indicar el correo del "dueño" de la imagen.
Esta medatada puede consultarse con el comando ```docker inspect```.

```bash
$ docker inspect prod-env:0.1
...
...
"Labels": {
    "maintainer": "ialmandos@conatel.com.uy"
}
...
...
```

```ADD```
---
Agrega un archivo o directorio desde el contexto al lugar especificado en el filesystem de la imagen.
La sintaxis es la siguiente `ADD <source> <destination>` siendo `<source>`el path al archivo en la máquina `host` y `<destination>` el path a la ubicación del archivo o directorio dentro del contenedor.

Para definir `<source>` se pueden utilizar wildcards, de esta forma `ADD configuracion?.txt /data/` agregará al directorio `/data` dentro del contenedor todos los archivos del contexto que comiencen con `configuracion` que luego tengan exactamente un caracter y que terminen con la extensión `.txt`

#### Ejercicio 5

1. Crear un directorio y navegar hacia él:

```bash
~$ mkdir contexto
~$ cd contexto
~/contexto$
```

2. Dentro del nuevo directorio crear 3 archivos vacios de la siguiente manera:

```bash
~/contexto$ touch archivo1.cfg archivo2.cfg archivo3.cfg
```

3. Dentro del mismo directorio crear un archivo Dockerfile con las siguientes líneas:

```dockerfile
FROM ubuntu
ADD <completar>
```

Donde dice \<completar> se debe escribir, en una única línea, el comando necesario para agregar al directorio `/data` de la imagen los tres archivos creados en el paso 2.

4. Construir una imagen a partir del Dockerfile:

```bash
~/contexto$ docker build -t nombredelaimagen .
```

5. Crear un contenedor a partir de la nueva imagen y verificar que los archivos están presentes en `/data`


```RUN```
---
Ejecuta un comando, por defecto con el shell `/bin/sh -c`, y hace un `commit` agregando una nueva capa a la imagen resultante una vez finalizada la ejecución del comando.

#### Ejercicio 6

1. Modificar el Dockerfile construido en el ejercicio anterior para que tenga una sentencia `RUN` que instale Python de la siguiente manera `apt-get update && apt-get install -y python3 `.
2. Volver a construir la imagen.
3. Crear un contenedor a partir de la imagen y verificar que Python está instalado de la siguiente manera:

```bash
root@08f5d92ad130:/# python3
Python 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> exit()
root@08f5d92ad130:/#
```



```CMD```
---

Comando a ejecutar **por defecto** en caso de que el usuario no especifique uno al correr ```docker run```.

#### Ejercicio 7

En este ejercicio haremos que, por defecto, los contenedores creados a partir de nuestra nueva imagen corran python en lugar de `bash`

1. En el Dockerfile que utilizamos en los dos ejercicios anteriores, agregar una línea al final de la siguiente manera: `CMD python3`.
2. Volver a construir la imagen.
3. Crear un contenedor a partir de la nueva imagen, pero no especificar un comando a ejecutar.
4. Verificar que al crearse, el contenedor nos deja posicionados en el interprete de Python.

## ```ENV```

Define variables de entorno para ser utilizadas dentro del Dockerfile o dentro del contenedor.

#### Ejercicio 8

En este ejercicio exploraremos como utilizar las variables de entorno cambiando el directorio "home" del contenedor.

1. Partiendo del Dockerfile utilizado anteriormente, agregar la siguiente líne `ENV HOME mi_casa`
2. Luego vamos a crear el directorio `mi_casa` dentro de la imagen agregando al Dockerfile la siguiente línea `RUN mkdir $HOME`
3. Volver a construir la imagen.
4. A partir de la nueva imagen, crear un contenedor y verficiar que al tipear `cd ~` quedamos posicionados dentro del directorio `mi_casa`. (recuerde que en el ejercicio anterior modificó el comando por defecto del contenedor, por lo que ahora para ejecutar `bash` hay que hacerlo explicitamente)


## Optimización de la construcción de imágenes

Antes de aprender como escribir nuestro archivo Dockerfile para generar nuestras imágenes de forma mas eficiente, es necesario entender como funciona el proceso de construcción de una imágen a bajo nivel.
Cuando creamos una imagen a partir de un archivo Dockerfile con el comando ```docker build```, lo que hace básicamente docker es tomar la imagen base especificada en la directiva ```FROM``` e ir ejecutando de forma secuencial los comandos especificados en las directivas ```RUN```, ejecutando implícitamente un ```docker commit``` luego de cada comando y almacenando la imagen resultante en cache local.
Por lo que, al final del día, tendremos almacenada nuestra imagen final y todas las imágenes intermedias que se fueron creando para llegar a la misma. Esta estructura de capas puede verse al ejecutar el siguiente comando:

```bash
$ docker history prod-env:0.1
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
--> Lineas omitidas para mayor claridad <--
1d20f906abf2        5 minutes ago       /bin/sh -c apt-get install -y python3-pip       259 MB              
262a82549ff1        17 minutes ago      /bin/sh -c apt-get install -y python3           37.28 MB            
65e5f33f7859        18 minutes ago      /bin/sh -c apt-get update                       38.81 MB            
c2b62f673858        21 minutes ago      /bin/sh -c #(nop)  CMD ["/bin/sh" "-c" "bash"   0 B                 
9c2c661471f1        21 minutes ago      /bin/sh -c #(nop) ADD file:f3324fde77ff764cb1   7 B                 
afafd17c2c9c        26 hours ago        /bin/sh -c #(nop)  LABEL maintainer=ialmandos   0 B                 
6a2f32de169d        3 months ago        /bin/sh -c #(nop)  CMD ["/bin/bash"]            0 B                 
<missing>           3 months ago        /bin/sh -c mkdir -p /run/systemd && echo 'doc   7 B                 
<missing>           3 months ago        /bin/sh -c sed -i 's/^#\s*\(deb.*universe\)$/   2.759 kB            
<missing>           3 months ago        /bin/sh -c rm -rf /var/lib/apt/lists/*          0 B                 
<missing>           3 months ago        /bin/sh -c set -xe   && echo '#!/bin/sh' > /u   745 B               
<missing>           3 months ago        /bin/sh -c #(nop) ADD file:b8a2c16d65e533a2bc   117.2 MB
```

El objetivo de la estructura de capas almacenadas en cache es optimizar el tiempo de construcción de las imagenes y el espacio en disco que consumen los contenedores, mas sobre esto [aquí](	https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/#images-and-layers). Este proceso funciona de la siguiente manera: al invocar ```docker build -t <nombre-de-la-imagen> .```,  lo que hace Docker es, antes de ejecutar cada directiva del archivo Dockerfile, fijarse si no hay en cache una imagen derivada de la directiva correspondiente y de todas las anteriores (comenzando por la directiva ```FROM``` que siempre es la primera). En caso de que encuentre una imagen que se corresponda con dicha directiva, se saltea el paso de la generación de la misma (porque ya está generada) y pasa a la siguiente directiva. Este proceso se repite hasta que alguna de las imágenes no se encuentre en cache local, en tal caso Docker crea dicha imagen **y todas las sucesivas**. Dicho de otra forma, una imagen está compuesta por capas **read-only** que contienen los archivos resultantes de las directivas ejecutadas desde el archivo Dockerfile; estas capas se construyen una sobre otra, de forma incremental, agregando los archivos "delta" (sólo la diferencia) entre una capa y otra. Dado que las capas son read-only, si una capa posterior modifica un archivo contenido en una capa anterior, es necesario copiar nuevamente el archivo completo en la capa posterior, siéndo esta última copia la que se utilizará. Esta forma de construir las imágenes como capas una sobre otra, tiene la implicancia de que si modificamos una capa "del medio", será necesario volver a generar todas las capas sucesivas, dado que las capas no son autocontenidas sino que se basan en su capa anterior incluyendo únicamente los "nuevos archivos".
Entender esto es la clave para generar archivos Dockerfile mas eficientes; veámoslo con un ejemplo.
Cuando construímos nuestra imagen ```prod-env:0.1``` cargamos en ella una archivo de configuración llamado ```config.txt```. Supongamos ahora que queremos cambiar dicho archivo porque nos interesa modificar la configuración de nuestra aplicación; como la línea ```ADD config.txt /settings/config.txt``` se encuentra en tercer lugar en el archivo Dockerfile, Docker se verá obligado a volver a generar todas las imágenes correspondientes a las líneas 4 en adelante. Si por el contrario nuestro archivo de configuración, que es lo único frecuentemente modificable de nuestra imagen, se encontrara en el último lugar, el proceso de reconstrucción de nuestra imagen sería mucho mas rápido. 

#### Ejercicio 9

1. Generar una nueva carpeta:

   ``` bash
   $ mkdir prod_env
   $ cd prod_env
   ```

2. Dentro de la nueva carpeta, generar un archivo de configuración:

   ``` bash
   prod-env/$ touch config.txt
   ```

3. Generar un archivo `Dockerfile` utilizando el comando `nano Dockerfile` y copiar el contenido que se muestra a continuación:

```
FROM ubuntu
LABEL maintainer="ialmandos@conatel.com.uy"
RUN apt-get update
RUN apt-get install -y python3
RUN apt-get install -y python3-pip
RUN pip3 install --upgrade pip
RUN pip3 install requests
RUN pip3 install mysql-connector==2.1.4
RUN pip3 install django==1.10
RUN echo "mysql-server mysql-server/root_password password C0n4t3l2017." | debconf-set-selections
RUN echo "mysql-server mysql-server/root_password_again password C0n4t3l2017." | debconf-set-selections
RUN apt-get install -y mysql-server
RUN apt-get install -y tftpd-hpa
RUN apt-get install -y openssh-server
RUN apt-get install -y nginx
# Colocamos el archivo config.txt al final de Dockerfile para que el build sea mas rapido
ADD config.txt /settings/config.txt
CMD bash
```

4. Construir la imagen.

```bash
$ docker build -t prod-env:0.2 .
--> Proceso largo, salida omitida para mayor claridad <--
```

5. Modificar el archivo de configuración.

```bash
$ nano configuracion.txt
...
```

6. Construir la nueva imagen.

```bash
$ docker build -t prod-env:0.3 .
Sending build context to Docker daemon 3.584 kB
Step 1 : FROM ubuntu
 ---> 6a2f32de169d
Step 2 : LABEL maintainer "ialmandos@conatel.com.uy"
 ---> Using cache
 ---> afafd17c2c9c
Step 3 : RUN apt-get update
 ---> Using cache
 ---> 573326a6e92c
Step 4 : RUN apt-get install -y python3
 ---> Using cache
 ---> 5bfb4979116a
Step 5 : RUN apt-get install -y python3-pip
 ---> Using cache
 ---> c61e1f9186a9
Step 6 : RUN pip3 install --upgrade pip
 ---> Using cache
 ---> a8c50dcc2edb
Step 7 : RUN pip3 install requests
 ---> Using cache
 ---> 839dc6e481dd
Step 8 : RUN pip3 install mysql-connector==2.1.4
 ---> Using cache
 ---> 5a79ea4f45e8
Step 9 : RUN pip3 install django==1.10
 ---> Using cache
 ---> 3e4141f48995
Step 10 : RUN echo "mysql-server mysql-server/root_password password C0n4t3l2017." | debconf-set-selections
 ---> Using cache
 ---> 127612294c11
Step 11 : RUN echo "mysql-server mysql-server/root_password_again password C0n4t3l2017." | debconf-set-selections
 ---> Using cache
 ---> 9dad58c90c5e
Step 12 : RUN apt-get install -y mysql-server
 ---> Using cache
 ---> e3890c3a7f44
Step 13 : RUN apt-get install -y tftpd-hpa
 ---> Using cache
 ---> 1ed09e6b67a8
Step 14 : RUN apt-get install -y openssh-server
 ---> Using cache
 ---> cb7c94f932b9
Step 15 : RUN apt-get install -y nginx
 ---> Using cache
 ---> e9dedac9236d
Step 16 : ADD config.txt /settings/config.txt
 ---> 3d8725e97b1d
Removing intermediate container f9220859e7e8
Step 17 : CMD bash
 ---> Running in 6ae16bd2cb01
 ---> ddcc775bb256
Removing intermediate container 6ae16bd2cb01
```

### Contenedores vs imágenes

Si bien conceptualmente las diferencias entre contenedores e imágenes son importantes, la realidad es que si análizamos uno y otro a bajo nivel, tienen una estructura casí idéntica. De hecho la imagen es parte del contenedor; veamos esto en mas detalle.
Un contenedor es una imagen a la que se le agrega una capa adicional con permisos de escritura. Esta capa contendrá todos los archivos que se generen en el contenedor mientras el mismo esté corriendo. Esta capa con permiso de escritura permanecerá en nuestro sistema haciendo persistentes los datos contenidos en ella mientras el contenedor exista; cuando borramos un contenedor de nuestro sistema con el comando ```docker rm <nombre-del-contenedor>``` lo que en realidad estamos haciendo es borrar esta última capa. La imagen a continuación muestra gráficamente la estructura de capas explicada anteriormente:

![alt text](Imagenes/container-layers.jpg "Estructura de capas de un contenedor")

La forma en que están estructurados los contenedores presenta un beneficio muy importante, y es que si corremos varios conenedores derivados de una misma imagen, el espacio que ocupará cada uno en disco será unicamente la sumatoria de todas las capas superiores (capas de contenedor) mas la imagen en sí, que se sumará una única vez. El diagrama a continuación muestra este concepto gráficamente:

![alt text](Imagenes/sharing-layers.jpg "Varios contenedores utilizando una imagen")

| [<-- Volver](20170801-Docker.md) |
[Siguiente -->](20170815-Storage.md) |
